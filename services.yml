stages:
  - prepare
  - deploy
  - deploy-charts
  - verify
  - cleanup

include:
  - services/alluxio.yml
  - services/batch-job.yml
  - services/frontend.yml
  - services/history.yml
  - services/metadata.yml
  - services/mysql.yml
  - services/spark-operator.yml
  - services/schema.yml
  - services/spark-dashboard.yml
  - services/zeppelin.yml
  - services/rbac.yml

variables:
  CHARTS_DIR: charts
  OVERRIDES_FILE: overrides.yml
  SERVICE_NAMESPACE: "${CI_PROJECT_NAME}-${CI_PROJECT_ID}-${ENV_NAME}"

.generator:
  # extenders need to generate a file "deployment/${PROJECT}.yml"
  stage: prepare
  image: ${CONTAINER_REGISTRY}alpine
  rules:
    - if: '($DEPLOY_PROJECT == "${PROJECT}" || $DEPLOY_PROJECT == "all") && $ONLY_CLEANUP == "false"'
  variables: {}
    # PROJECT
  artifacts:
    paths:
      - ${DEPLOYMENTS_DIR}/${PROJECT}.yml

.helm-prepare:
  stage: prepare
  extends:
    - .package-pull
  variables: {}
    # SERVICE_NAME:
    # PACKAGE_NAME:
    # FILE_NAME:
    # PACKAGE_VERSION:
    # ID:
  before_script:
    - mkdir -p ${CHARTS_DIR}/${SERVICE_NAME}/
    - cd ${CHARTS_DIR}/${SERVICE_NAME}/
  artifacts:
    paths:
      - ${CHARTS_DIR}

.verify-running:
  stage: verify
  extends:
    - .environment
  rules:
    - if: '$UPSTREAM_PROJECT == "metadata"'
  variables:
    TIMEOUT: "60"
    # SERVICE_NAME:
    # SERVICE_LABEL:
    # PROJECT:"
  script:
    - |
      while [ $(kubectl get pod -l ${SERVICE_LABEL} -o jsonpath="{.items[0].status.phase}") != 'Running' ]; do
       if [[ ${TIMEOUT} -le 0 ]]
        then
          echo "Timed out waiting; pod status $(kubectl get pod -l ${SERVICE_LABEL} -o jsonpath="{.items[0].status.phase}") != 'Running'"
          exit 1
        fi
       TIMEOUT=$((TIMEOUT-1))
       sleep 1
      done
    - kubectl describe pods -l ${SERVICE_LABEL}
    - echo -e "\n LOGS -------- \n"
    - kubectl logs $(kubectl get pod -l ${SERVICE_LABEL} -o jsonpath="{.items[0].metadata.name}") --all-containers=true


.verify-cleanup:
  stage: cleanup
  rules:
    - if: '$UPSTREAM_PROJECT == "metadata"'
      when: manual
      allow_failure: true
  extends:
    - .environment
  variables:
    TIMEOUT: "60"
    # SERVICE_NAME:
    # SERVICE_LABEL:
    # PROJECT:"
  script:

    - helm uninstall ${SERVICE_NAME} || true
    - kubectl delete service/${MYSQL_SERVICE_NAME} deployment/${MYSQL_SERVICE_NAME} || true

Deploy resources:
  # Deploy all generated resource configs in the deployments directory
  # Also install helm charts by explicitly referencing sub-scripts
  stage: deploy
  rules:
    - if: '$ONLY_CLEANUP == "false"'
  extends:
    - .environment
  script:
    - |
      if ! kubectl get sa spark
      then
        echo "Creating 'spark' service account"
        kubectl apply -f - <<EOF
        apiVersion: v1
        kind: ServiceAccount
        metadata:
          name: spark
          namespace: ${SERVICE_NAMESPACE}
      EOF
      fi

      if [ -d "${DEPLOYMENTS_DIR}/" ] 
      then
        echo "Deploying the following files"
        ls ${DEPLOYMENTS_DIR}/
        kubectl apply -f ${DEPLOYMENTS_DIR}/
      else
        echo "No resources to deploy"
      fi

Deploy helm charts:
  # Install all helm charts
  stage: deploy-charts
  rules:
    - if: '$ONLY_CLEANUP == "false"'
  extends:
    - .environment
  script:
    - |
      ls -lRt ${CHARTS_DIR}/
      if [ -d "${CHARTS_DIR}/" ]
      then
        for SERVICE in $(ls ${CHARTS_DIR}) ; do
          [[ ${ENABLE_ALLUXIO} -eq 0 ]] && [[ ${SERVICE} == "alluxio" ]] && continue

          echo "Installing/upgrading service ${SERVICE}..."

          echo "helm upgrade --install --values ${CHARTS_DIR}/${SERVICE}/${OVERRIDES_FILE} ${SERVICE} ${CHARTS_DIR}/${SERVICE}/*.tgz"
          helm upgrade --install --values ${CHARTS_DIR}/${SERVICE}/${OVERRIDES_FILE} ${SERVICE} ${CHARTS_DIR}/${SERVICE}/*.tgz
        done
      else
        echo "No helm charts to deploy"
      fi

Cleanup services:
  # Remove all services
  stage: cleanup
  rules:
    - if: '$ONLY_CLEANUP == "true"'
  extends:
    - .environment
  dependencies: [] # skip downloading any artifacts
  variables:
    TIMEOUT: "60"
  script:
    - kubectl exec ${ALLUXIO_SVC} -c alluxio-master -- alluxio fs rm -RU /${SPARK_WAREHOUSE} || true
    - kubectl exec ${ALLUXIO_SVC} -c alluxio-master -- alluxio fs rm -RU /${SPARK_DEPENDENCY_DIR} || true
    - helm uninstall ${ALLUXIO_SERVICE_NAME} alluxio-charts/alluxio || true
    - kubectl delete pod ${SPARK_DRIVER_POD_NAME} --ignore-not-found=true
    - kubectl delete service/${MYSQL_SERVICE_NAME} deployment/${MYSQL_SERVICE_NAME} || true
    - helm uninstall ${ZEPPELIN_SERVICE_NAME} || true
    - helm uninstall ${SCHEMA_SERVICE_NAME} || true
    - helm uninstall ${METADATA_SERVICE_NAME} || true
    - helm uninstall ${HISTORY_SERVICE_NAME} || true
    - helm uninstall ${FRONTEND_SERVICE_NAME} || true
    - helm uninstall ${BATCH_JOB_SERVICE_NAME} || true
    - helm uninstall ${SPARK_OPERATOR_SERVICE_NAME} || true
    - helm uninstall ${SPARK_DASHBOARD_SERVICE_NAME} || true
    - helm uninstall ${RBAC_SERVICE_NAME} || true
    - kubectl delete sa ${SPARK_OPERATOR_SERVICE_NAME} || true
    - echo "Waiting for resources to cleanup..."
    - |
      while [[ $(kubectl get pods --no-headers | wc -l) -gt 0 ]] &&
            [[ $(kubectl get services --no-headers | wc -l) -gt 0 ]]
      do
        if [[ ${TIMEOUT} -le 0 ]]
        then
          echo "Timed out waiting for resources to cleanup"
          exit 1
        fi
        TIMEOUT=$((TIMEOUT-1))
        sleep 1
      done
      kubectl delete secret ${PULL_SECRET} --ignore-not-found=true