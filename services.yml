stages:
  - prepare
  - deploy
  - deploy-charts
  - verify
  - cleanup

include:
  - services/alluxio.yml
  - services/batch-job.yml
  - services/frontend.yml
  - services/history.yml
  - services/metadata.yml
  - services/mysql.yml
  - services/spark-operator.yml
  - services/schema.yml
  - services/spark-dashboard.yml
  - services/zeppelin.yml

variables:
  CHARTS_DIR: charts
  OVERRIDES_FILE: overrides.yml
  SERVICE_NAMESPACE: staging-48-testing

.generator:
  # extenders need to generate a file "deployment/${PROJECT}.yml"
  stage: prepare
  image: ${CONTAINER_REGISTRY}alpine
  rules:
    - if: '($DEPLOY_PROJECT == "${PROJECT}" || $DEPLOY_PROJECT == "all") && $ONLY_CLEANUP == "false"'
  variables: {}
    # PROJECT
  artifacts:
    paths:
      - ${DEPLOYMENTS_DIR}/${PROJECT}.yml

.helm-prepare:
  stage: prepare
  extends:
    - .package-pull
  variables: {}
    # SERVICE_NAME:
    # PACKAGE_NAME:
    # FILE_NAME:
    # PACKAGE_VERSION:
    # ID:
  before_script:
    - mkdir -p ${CHARTS_DIR}/${SERVICE_NAME}/
    - cd ${CHARTS_DIR}/${SERVICE_NAME}/
  artifacts:
    paths:
      - ${CHARTS_DIR}

.verify-running:
  stage: verify
  extends:
    - .environment
  rules:
    - if: '$UPSTREAM_PROJECT == "metadata"'
  variables:
    TIMEOUT: "60"
    # SERVICE_NAME:
    # SERVICE_LABEL:
    # PROJECT:"
  script:
    - |
      while [ $(kubectl get pod -l ${SERVICE_LABEL} -o jsonpath="{.items[0].status.phase}") != 'Running' ]; do
       if [[ ${TIMEOUT} -le 0 ]]
        then
          echo "Timed out waiting; pod status $(kubectl get pod -l ${SERVICE_LABEL} -o jsonpath="{.items[0].status.phase}") != 'Running'"
          exit 1
        fi
       TIMEOUT=$((TIMEOUT-1))
       sleep 1
      done
    - kubectl describe pods -l ${SERVICE_LABEL}
    - echo -e "\n LOGS -------- \n"
    - kubectl logs $(kubectl get pod -l ${SERVICE_LABEL} -o jsonpath="{.items[0].metadata.name}") --all-containers=true


.verify-cleanup:
  stage: cleanup
  rules:
    - if: '$UPSTREAM_PROJECT == "metadata"'
      when: manual
      allow_failure: true
  extends:
    - .environment
  variables:
    TIMEOUT: "60"
    # SERVICE_NAME:
    # SERVICE_LABEL:
    # PROJECT:"
  script:

    - helm uninstall ${SERVICE_NAME} || true
    - kubectl delete service/${MYSQL_SERVICE_NAME} deployment/${MYSQL_SERVICE_NAME} || true

Deploy resources:
  # Deploy all generated resource configs in the deployments directory
  # Also install helm charts by explicitly referencing sub-scripts
  stage: deploy
  rules:
    - if: '$ONLY_CLEANUP == "false"'
  extends:
    - .environment
  script:
    - |
      if [ -d "${DEPLOYMENTS_DIR}/" ] 
      then
        echo "Deploying the following files"
        ls ${DEPLOYMENTS_DIR}/
        kubectl apply -f ${DEPLOYMENTS_DIR}/
      else
        echo "No resources to deploy"
      fi

Deploy helm charts:
  # Install all helm charts
  stage: deploy-charts
  rules:
    - if: '$ONLY_CLEANUP == "false"'
  extends:
    - .environment
  script:
    - |
      if [ -d "${CHARTS_DIR}/" ]
      then
        for SERVICE in $(ls ${CHARTS_DIR}) ; do
          echo "Installing/upgrading service ${SERVICE}..."
          helm upgrade --install --values ${CHARTS_DIR}/${SERVICE}/${OVERRIDES_FILE} ${SERVICE} ${CHARTS_DIR}/${SERVICE}/*.tgz
        done
      else
        echo "No helm charts to deploy"
      fi

Cleanup services:
  # Remove all services
  stage: cleanup
  rules:
    - if: '$ONLY_CLEANUP == "true"'
  extends:
    - .environment
  dependencies: [] # skip downloading any artifacts
  variables:
    TIMEOUT: "60"
  script:
    - |
      if [[ ${ALLUXIO_ENABLED} -eq 1 ]]
      then
        kubectl exec ${ALLUXIO_SVC} -c alluxio-master -- alluxio fs rm -RU /${SPARK_WAREHOUSE} || true
        kubectl exec ${ALLUXIO_SVC} -c alluxio-master -- alluxio fs rm -RU /${SPARK_DEPENDENCY_DIR} || true
      fi

      if [[ $(kubectl get pods --no-headers | wc -l) -gt 0 ]]
      then
        echo ""
        echo "Follwoing services will be cleaned up:"
        kubectl get pods
        echo "---------------------------------"

        echo "echo"
        echo "Following helm installs will be cleaned up:"
        helm list

        for service in `helm list | grep -v NAME | awk '{print $1}'`
        do
          echo "Uninstalling $service..."
          helm uninstall ${service}
        done

        kubectl get pod mysql -n n1  2>1 /dev/null
        if [[ $? -eq 0 ]]
        then
          echo "Deleting mysql deployment"
          kubectl delete deployment mysql

          echo "Deleting mysql account"
          kubectl delete service mysql
        fi

        for p in `kubectl get pods | grep -v NAME | awk '{print $1}'`
        do
          print_log "deleting pod $p"
          kubectl delete pod $p
        done

        while [[ $(kubectl get pods --no-headers | wc -l) -gt 0 ]] &&
              [[ $(kubectl get services --no-headers | wc -l) -gt 0 ]]
        do
          if [[ ${TIMEOUT} -le 0 ]]
          then
            echo "Timed out waiting for resources to cleanup"
            exit 1
          fi
          TIMEOUT=$((TIMEOUT-1))
          sleep 1
          echo "Waiting for services/pods to be cleaned up"
        done
      fi

      for service in `kubectl get sa | grep -v NAME | awk '{print $1}'`
      do
        echo "Deleting service account $service"
        kubectl delete sa $service
      done