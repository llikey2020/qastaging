# Include this template to deploy to an environment defined in a skeleton job like this:
#
# .environment:
#   tags: ["${CI_RUNNER_TAG}"]
#   environment: testing
#
# And define the following variables in the project's Settings -> CI/CD -> Variables:
# - ALLUXIO_UFS
# - AWS_S3_ACCESS_KEY_ID
# - AWS_S3_SECRET_ACCESS_KEY
#
# Other variables that the includer could override:
# - REGISTRY
# - REGISTRY_USER
# - REGISTRY_PASSWORD

default:
  # Use the k8s tooling image by default
  image: ${CI_REGISTRY}/planetrover/infrastructure/k8s

include:
  - project: planetrover/templates
    file: templates.yml
  - services.yml

variables:
  DEPLOY_PROJECT:
    value: all
    description: all, alluxio, batchJob, frontend, history, hive, metadata, mysql, schema, sparkDashboard, sparkOperator, zeppelin, rbac
  ONLY_CLEANUP: 
    value: "false"
    description: Skip cleanup when false, only run cleanup when true
  ALLUXIO_VERSION: 2.6.0
  ENABLE_ALLUXIO:
    value: 0
    description: set to 1 to support Alluxio file storage
  REPLICA_COUNT: 1
  BATCH_JOB_IMAGE_TAG: latest
  FRONTEND_IMAGE_TAG: latest
  SCHEMA_IMAGE_TAG: latest
  SPARK_IMAGE_TAG: latest
  ZEPPELIN_IMAGE_TAG: latest
  METADATA_IMAGE_TAG: latest
  RBAC_IMAGE_TAG: latest
  SPARK_DRIVER_MEMORY: 2g
  SPARK_EXECUTOR_MEMORY: 2g
  SPARK_EXECUTOR_CORES: 1
  SPARK_EXECUTOR_REQUEST_CORES: 1000m
  SPARK_DYNAMIC_ALLOCATION_ENABLED: "false"
  SPARK_DYNAMIC_ALLOCATION_MAX_EXECUTORS: 4
  SPARK_DYNAMIC_ALLOCATION_MIN_EXECUTORS: 2
  CACHE_SSD_SIZE: 10G
  SPARK_WAREHOUSE: spark-warehouse
  SPARK_SQL_PERF_JAR: spark-sql-perf_2.12-0.5.1-SNAPSHOT.jar
  SPARK_DEPENDENCY_DIR: spark-files/
  SPARK_EVENTLOG_DIR: spark-logs
  SPARK_DRIVER_POD_NAME: spark-driver
  SPARK_SERVICE_ACCOUNT: spark
  MYSQL_VERSION: "5.7"
  MYSQL_ROOT_PASSWORD: password
  METASTORE_DATABASE: metastore
  DEPLOYMENTS_DIR: deployments
  PULL_SECRET: docker-login
  PLANETROVER_PULL_SECRET: planetrover-registry
  REGISTRY: ${CI_REGISTRY}
  REGISTRY_USER: ${SEQUOIADP_DEPLOY_TOKEN_USERNAME}
  REGISTRY_PASSWORD: ${SEQUOIADP_DEPLOY_TOKEN_PASSWORD}
  SPARK_PROJECT: sequoiadp/spark
  SPARK_PROJECT_ID: 2
  TIME_ZONE: Canada/Eastern

Registry login:
  # Login to the docker registry and create the secret used for pulling images
  stage: prepare
  rules:
    - if: '$ONLY_CLEANUP == "false"'
  extends:
    - .environment
  script:
    - |
      env | sort

      kubectl cluster-info

      kubectl get ns

      if ! kubectl get ns | grep -w ${SERVICE_NAMESPACE}
      then
        kubectl create ns ${SERVICE_NAMESPACE}
      fi

      if ! kubectl get secret ${PULL_SECRET} -n ${SERVICE_NAMESPACE}
      then
        kubectl create secret docker-registry ${PULL_SECRET} \
        --namespace=${SERVICE_NAMESPACE} \
        --docker-server=${REGISTRY} \
        --docker-username=${REGISTRY_USER} \
        --docker-password=${REGISTRY_PASSWORD}
      fi

      if ! kubectl get secret ${PLANETROVER_PULL_SECRET} -n ${SERVICE_NAMESPACE}
      then
        kubectl create secret docker-registry ${PLANETROVER_PULL_SECRET} \
        --namespace=${SERVICE_NAMESPACE} \
        --docker-server=${REGISTRY} \
        --docker-username=${PLANETROVER_REGISTRY_USERNAME} \
        --docker-password=${PLANETROVER_REGISTRY_PASSWORD}
      fi

Setup environment:
  stage: .pre
  rules:
    - if: '$ONLY_CLEANUP == "false"'
  extends:
    - .environment
  script:
    - |
      env | sort
      kubectl cluster-info

      for i in BATCH_JOB FRONTEND SCHEMA SPARK METADATA ZEPPELIN RBAC
      do
        IMAGE_TAG=${i}_IMAGE_TAG
        PROJECT_ID=${i}_PROJECT_ID
        if [ ${!IMAGE_TAG} = "latest" ]
        then
          echo "${IMAGE_TAG}=$(curl --header "PRIVATE-TOKEN: ${CI_API_TOKEN}" "${CI_API_V4_URL}/projects/${!PROJECT_ID}/repository/commits/master" | jq -r '.id')" >> staging.env
        else
          echo "${IMAGE_TAG}=${!IMAGE_TAG}" >> staging.env
        fi
      done
      source staging.env
      env | sort
  after_script:
    - cat staging.env
  artifacts:
    reports:
      dotenv: staging.env
